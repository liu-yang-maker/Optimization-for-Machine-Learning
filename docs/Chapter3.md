# 确定性凸优化算法

Deterministic Convex Optimization

[TOC]

在本章中，我们研究解决凸优化问题的算法。 我们将重点放在已应用或有潜力用于解决机器学习和其他数据分析问题的算法。 更具体地说，我们将讨论已被证明对大规模优化有效的一阶方法。 这些方法还构成了其他计算效率高的方法的基础，例如，将在后面的章节中讨论的随机方法。

## 子梯度下降

我们将从最简单的梯度下降方法开始，用来极小化一个可微的凸函数 $f$，从初始点 $x_1$ 开始，梯度下降的每次更新步按照下面这个公式进行：
$$
x_{t+1}=x_{t}-\gamma_{t} \nabla f\left(x_{t}\right), t=1,2, \ldots
$$


## 加速梯度下降

## 原始对偶方法

## 交替乘子下降法